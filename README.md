# TensorFlowLearn
## Лабораторная работа
Создадим модель TensorFlow.js для распознавания рукописных цифр с помощью сверточной нейронной сети

1. Столкнулся с CORS при тестировании в браузере. Т.к. использую VS Code, то воспользовался расширением Live Server. "Hello TensorFlow" в консоль получил.
2. Картинки загрузились и отобразились в окне браузера. При этом в консоле получено сообщение:
```
Canvas2D: Multiple readback operations using getImageData are faster with the willReadFrequently attribute set to true. See: https://html.spec.whatwg.org/multipage/canvas.html#concept-canvas-will-read-frequently
img.onload @ data.js:68
load (async)
(anonymous) @ data.js:49
load @ data.js:47
run @ script.js:35
```
3. Самая мякотка: нужно правильно задать описание входных данных и те фукции активации, по которым будет производиться обучение каждого слоя.
Обратил тут внимание на используемую переменную `tf`. Пока не понял где она объявляется (tf.min.js?).

Ссылки для изучения:
* https://setosa.io/ev/image-kernels/ (свёрточные алгоритмы для изображений)
* https://cs231n.github.io/convolutional-networks/ (большая статья на английском с картинками)

4. Была добавлена функция для вызова тренинга и проверки, с одновременной визуализацией процесса обучения модели. Попробовал увеличить датасет, справляется.
5. Более подробная разбивка производительности по различным классам.

## Начинаем новый датасет
Расположил категории в папке `./data_my`

Установил пакет
```shell
npm i @tensorflow/tfjs-node --ignore-scripts
```
(но он не хочет загружаться, вернулся к варианту с tf.min.js)

Размер изображений 640*480 (307200 пикселей, 8-bit gamma integer). RGB следует нормализовать. Весь массив перетасовывается, чтобы не получилось так, что для теста останутся только данные из хвоста датасета, ничто из которого не попадет в обучающую выборку.
```JavaScript
tf.util.shuffleCombo(INPUTS, OUTPUTS);
```
Теперь массивы преобразутся в тензоры. После этого строится архитектура.

2 скрытых слоя с 100 и 7 нейронами. У каждого нейрона есть своя функция активации. Этим двум подходит relu.

Количество категорий - 14. Выходные вероятности представляются в виде 1-hot кодирования, означающего, что будут вычисляться все 14 ячеек в одномерном массиве.

Функция активации softmax в выходном слое гарантирует, что сумма всех нейронов будет равняться 1, т.е. вероятности будут распределены по всем категориям.

Наконец нужно будет указать функцию потерь "кроссэнтропия".
Это называется сеть классификации, а не выполняющую регрессию.

Обучение будет проходить за 17 эпох.